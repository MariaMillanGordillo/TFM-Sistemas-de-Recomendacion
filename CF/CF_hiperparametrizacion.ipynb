{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyfW9do5L7qN"
      },
      "source": [
        "# Collaborative Filtering: Hiperparametrización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdGvN7QZL7qP"
      },
      "source": [
        "## Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSXdRuMmHEnB",
        "outputId": "9b5393cc-dca7-4dfe-d17e-7f52e8d0193c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.0+cu121\n",
            "12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FP2VokylHP-D",
        "outputId": "c53f287e-51df-4bee-930d-876b94cdc29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Reinstala PyTorch 2.3.0 con CUDA 12.1 (estable en Colab)\n",
        "!pip install torch==2.3.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Instala PyG y extensiones con soporte oficial\n",
        "!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv \\\n",
        "  -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7l2aPm9KMAh",
        "outputId": "4ca651dd-a18d-4a80-ca33-9db142630e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import nn, optim, Tensor\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mZ6-zPxPklE"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YR6zOgBL7qU"
      },
      "source": [
        "### Definición de funciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-pEew9IL7qU"
      },
      "source": [
        "Comenzamos definiendo las funciones necesarias para construir los nodos y las aristas del grafo a partir de los datos de usuarios, libros e interacciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IRcrJtxOL7qU"
      },
      "outputs": [],
      "source": [
        "# Cargar nodos de usuarios y libros\n",
        "def load_node_csv(path, index_col):\n",
        "    \"\"\"\n",
        "    Carga un CSV que contiene información sobre los nodos.\n",
        "\n",
        "    Args:\n",
        "        path (str): Ruta al archivo CSV.\n",
        "        index_col (str): Nombre de la columna que se usará como índice.\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario que mapea los valores del índice del CSV a IDs de nodo.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path, index_col=index_col)\n",
        "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
        "    return mapping\n",
        "\n",
        "# Cargar aristas entre usuarios y libros\n",
        "def load_edge_csv(df, src_index_col, src_mapping, dst_index_col, dst_mapping, link_index_col, rating_threshold=4):\n",
        "    \"\"\"\n",
        "    Carga aristas entre usuarios e ítems (por ejemplo, libros) a partir de un DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): DataFrame que contiene las interacciones usuario-ítem.\n",
        "        src_index_col (str): Nombre de la columna con los IDs de usuario.\n",
        "        src_mapping (dict): Diccionario que mapea los IDs de usuario a índices de nodo.\n",
        "        dst_index_col (str): Nombre de la columna con los IDs de ítems.\n",
        "        dst_mapping (dict): Diccionario que mapea los IDs de ítems a índices de nodo.\n",
        "        link_index_col (str): Nombre de la columna que contiene la interacción (por ejemplo, rating).\n",
        "        rating_threshold (int, opcional): Umbral mínimo para considerar una interacción como positiva. Por defecto es 4.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Matriz 2xN que contiene los pares de nodos conectados por N aristas.\n",
        "    \"\"\"\n",
        "    src = [src_mapping[index] for index in df[src_index_col]]\n",
        "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "\n",
        "    return torch.tensor(edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkTXSLDXL7qV"
      },
      "source": [
        "Implementamos una función que realiza muestreo estructurado negativo para generar mini-batches compuestos por usuarios, ítems positivos e ítems negativos, necesarios para entrenar el modelo basado en grafos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZWfXTMjQL7qV"
      },
      "outputs": [],
      "source": [
        "# Función que selecciona aleatoriamente un mini-lote de muestras positivas y negativas\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"\n",
        "    Selecciona aleatoriamente los índices de un mini-lote dado un grafo de adyacencia.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): tamaño del mini-lote\n",
        "        edge_index (torch.Tensor): matriz 2 x N con los bordes del grafo\n",
        "\n",
        "    Returns:\n",
        "        tuple: índices de usuarios, índices de ítems positivos, índices de ítems negativos\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTaQIIlGL7qW"
      },
      "source": [
        "### Cargamos y filtramos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dZkyHrgq4ZG_"
      },
      "outputs": [],
      "source": [
        "user_id_path = '/content/user_id_map.csv'\n",
        "book_id_path = '/content/book_id_map.csv'\n",
        "interactions_path = '/content/interactions_filtered.csv'\n",
        "books_path = '/content/books_authors_genres.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JhtJn8Oh7ZA9"
      },
      "outputs": [],
      "source": [
        "interactions = pd.read_csv(interactions_path)\n",
        "books = pd.read_csv(books_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwUCWmk6L7qY"
      },
      "source": [
        "Aplicamos un filtrado para eliminar ítems con pocas interacciones y usuarios poco activos, mejorando así la calidad del grafo de interacciones. Esto reduce la dispersión y mejora el aprendizaje del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC_pTUUfVZ1c",
        "outputId": "42ddbeff-0c10-4eee-9771-c1fa6568d286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interactions filtrado: (16803, 5)\n",
            "num_users=3310, num_items=947\n"
          ]
        }
      ],
      "source": [
        "item_inter_counts = interactions.groupby(\"book_id\").size()\n",
        "popular_books = item_inter_counts[item_inter_counts >= 10].index\n",
        "interactions = interactions[interactions[\"book_id\"].isin(popular_books)]\n",
        "\n",
        "user_inter_counts = interactions.groupby('user_id').size()\n",
        "active_users = user_inter_counts[user_inter_counts >= 4].index\n",
        "interactions = interactions[interactions['user_id'].isin(active_users)]\n",
        "\n",
        "print(f\"Interactions filtrado: {interactions.shape}\")\n",
        "\n",
        "num_users = interactions['user_id'].nunique()\n",
        "num_items = interactions['book_id'].nunique()\n",
        "print(f\"{num_users=}, {num_items=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu-dzOOqL7qZ"
      },
      "source": [
        "Aplicamos las funciones para crear los nodos y las aristas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "icRx9ghUL7qZ"
      },
      "outputs": [],
      "source": [
        "user_mapping = load_node_csv(user_id_path, index_col='user_id_csv')\n",
        "book_mapping = load_node_csv(book_id_path, index_col='book_id_csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "180oZoqtL7qa",
        "outputId": "400d9485-34a7-42b2-874b-9fef5f11b30b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "edge_index: tensor([[    14,     14,     14,  ..., 873215, 873215, 873215],\n",
            "        [ 11831,  10943,  10570,  ...,  39638,  39637,  39640]])\n",
            "edge_index.shape: torch.Size([2, 16803])\n"
          ]
        }
      ],
      "source": [
        "edge_index = load_edge_csv(\n",
        "    interactions,\n",
        "    src_index_col='user_id',\n",
        "    src_mapping=user_mapping,\n",
        "    dst_index_col='book_id',\n",
        "    dst_mapping=book_mapping,\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=4\n",
        ")\n",
        "\n",
        "# Verifica la forma de edge_index\n",
        "print(\"edge_index:\", edge_index)\n",
        "print(\"edge_index.shape:\", edge_index.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhADXoQ-L7qa"
      },
      "source": [
        "Dividimos las interacciones del grafo entre usuarios y libros en tres subconjuntos: entrenamiento, validación y prueba, siguiendo una proporción del 80%, 10% y 10% respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wIueYZfaT6_H"
      },
      "outputs": [],
      "source": [
        "# Dividir los bordes del grafo en un 80/10/10 para entrenamiento, validación y prueba\n",
        "num_users, num_books = len(user_mapping), len(book_mapping)\n",
        "num_interacciones = edge_index.shape[1]\n",
        "todos_los_indices = [i for i in range(num_interacciones)]\n",
        "\n",
        "# 80% entrenamiento, 10% validación y 10% prueba\n",
        "train_indices, test_indices = train_test_split(todos_los_indices, test_size=0.2, random_state=1)\n",
        "val_indices, test_indices = train_test_split(test_indices, test_size=0.5, random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvtd0QIz7xFI",
        "outputId": "6a1a2344-84e1-4b87-8dec-a8e00e396f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_edge_index.shape: torch.Size([2, 13442])\n",
            "val_edge_index.shape: torch.Size([2, 1680])\n",
            "test_edge_index.shape: torch.Size([2, 1681])\n"
          ]
        }
      ],
      "source": [
        "print(\"train_edge_index.shape:\", train_edge_index.shape)\n",
        "print(\"val_edge_index.shape:\", val_edge_index.shape)\n",
        "print(\"test_edge_index.shape:\", test_edge_index.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3R9otM0L7qb"
      },
      "source": [
        "Convertimos los índices de los bordes del grafo en tensores dispersos (SparseTensor) para optimizar el almacenamiento y las operaciones sobre grafos grandes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U5yKILBJUAN6"
      },
      "outputs": [],
      "source": [
        "train_sparse_edge_index = SparseTensor(\n",
        "    row=train_edge_index[0],\n",
        "    col=train_edge_index[1],\n",
        "    sparse_sizes=(num_users + num_books, num_users + num_books)\n",
        ")\n",
        "\n",
        "val_sparse_edge_index = SparseTensor(\n",
        "    row=val_edge_index[0],\n",
        "    col=val_edge_index[1],\n",
        "    sparse_sizes=(num_users + num_books, num_users + num_books)\n",
        ")\n",
        "\n",
        "test_sparse_edge_index = SparseTensor(\n",
        "    row=test_edge_index[0],\n",
        "    col=test_edge_index[1],\n",
        "    sparse_sizes=(num_users + num_books, num_users + num_books)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "## Implementación de LightGCN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od8fjtTSL7qc"
      },
      "source": [
        "### Definición del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SHCiS35L7qc"
      },
      "source": [
        "A continuación, definimos el modelo LightGCN (Light Graph Convolutional Network), una red neuronal propuesta en el artículo LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation.\n",
        "\n",
        "Este modelo está diseñado específicamente para sistemas de recomendación, eliminando componentes innecesarios como funciones de activación o capas de proyección, y enfocándose únicamente en la agregación de embeddings a lo largo de un grafo bipartito de usuarios e ítems.\n",
        "\n",
        "La idea principal es realizar una propagación de mensajes ligera a través del grafo para capturar la estructura de las interacciones.\n",
        "El modelo inicializa embeddings para usuarios e ítems, y luego los actualiza mediante varias capas de propagación sobre la matriz de adyacencia normalizada. Finalmente, se promedia la información agregada en cada capa para obtener una representación final que captura diferentes niveles de conectividad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "outputs": [],
      "source": [
        "# Definimos el modelo LightGCN\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"\n",
        "    Modelo LightGCN propuesto en https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=16, K=2, add_self_loops=False):\n",
        "        \"\"\"\n",
        "        Inicializa el modelo LightGCN.\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Número de usuarios\n",
        "            num_items (int): Número de ítems (libros)\n",
        "            embedding_dim (int, opcional): Dimensión de los embeddings. Por defecto 16.\n",
        "            K (int, opcional): Número de capas de propagación de mensajes. Por defecto 2.\n",
        "            add_self_loops (bool, opcional): Si se añaden bucles propios en la propagación. Por defecto False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        # Embeddings iniciales de usuarios e ítems: e_u^0 y e_i^0\n",
        "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim)\n",
        "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim)\n",
        "\n",
        "        # Inicializamos los embeddings de usuarios e ítems con una distribución normal\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"\n",
        "        Propagación hacia adelante del modelo LightGCN.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): Matriz de adyacencia\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): Embeddings finales y originales de usuarios e ítems (e_u^K, e_u^0, e_i^K, e_i^0)\n",
        "        \"\"\"\n",
        "        # Calculamos \\tilde{A}: matriz de adyacencia normalizada simétricamente\n",
        "        edge_index_norm = gcn_norm(edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        # Embedding inicial conjunto E^0 (usuarios + ítems)\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # Propagación por K capas\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        # Promedio de los embeddings generados en cada capa (E^K)\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1)\n",
        "\n",
        "        # Separamos e_u^K y e_i^K (representaciones finales de usuarios e ítems)\n",
        "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
        "\n",
        "        # Devolvemos embeddings finales y los embeddings originales (iniciales)\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        \"\"\"Devuelve los mensajes recibidos de los nodos vecinos.\"\"\"\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        \"\"\"Multiplica la matriz de adyacencia normalizada con los embeddings.\"\"\"\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "# Instanciamos el modelo\n",
        "model = LightGCN(num_users, num_books)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "### Función de pérdida"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1iPZB29L7qd"
      },
      "source": [
        "Utilizamos la pérdida `Bayesian Personalized Ranking (BPR)`, una función de tipo comparativa por pares que favorece que, para cada usuario, las predicciones asociadas a ejemplos positivos sean más altas que las de los ejemplos negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"\n",
        "    Función de pérdida Bayesian Personalized Ranking, descrita en https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): e_i_k de los ítems positivos\n",
        "        pos_items_emb_0 (torch.Tensor): e_i_0 de los ítems positivos\n",
        "        neg_items_emb_final (torch.Tensor): e_i_k de los ítems negativos\n",
        "        neg_items_emb_0 (torch.Tensor): e_i_0 de los ítems negativos\n",
        "        lambda_val (float): valor lambda para el término de regularización\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: valor escalar de la pérdida BPR\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2))  # Pérdida L2\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1)  # Puntuaciones predichas de los ejemplos positivos\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1)  # Puntuaciones predichas de los ejemplos negativos\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "### Métricas de evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1SNP_KKL7qf"
      },
      "source": [
        "Para evaluar la el sistema de recomendación, empleamos métricas estándar centradas en las primeras posiciones del ranking generado para cada usuario. Concretamente, utilizamos `precisión@20`, `recall@20` y `nDCG@20`, que nos permiten medir tanto la relevancia como la ordenación de los ítems recomendados. Estas métricas se enfocan en los 20 primeros elementos recomendados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "outputs": [],
      "source": [
        "# Función auxiliar para obtener N_u (ítems positivos por usuario)\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"\n",
        "    Genera un diccionario con los ítems positivos para cada usuario\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): lista de aristas de tamaño 2 por N\n",
        "\n",
        "    Returns:\n",
        "        dict: diccionario con los ítems positivos de cada usuario\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "outputs": [],
      "source": [
        "# Calcula recall@K y precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"\n",
        "    Calcula recall @ k y precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): lista de listas con los ítems altamente valorados por cada usuario\n",
        "        r (list): lista de listas que indica si cada ítem recomendado en top k para cada usuario\n",
        "            es un ítem relevante en el top k ground truth o no\n",
        "        k (int): determina los primeros k ítems para calcular precision y recall\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # Número de ítems correctamente predichos por usuario\n",
        "    # Número de ítems que cada usuario valoró positivamente en el conjunto de prueba\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9v4A3Ek4TE02"
      },
      "outputs": [],
      "source": [
        "# Calcula NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"\n",
        "    Calcula Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): lista de listas con los ítems altamente valorados por cada usuario\n",
        "        r (list): lista de listas que indica si cada ítem recomendado en top k para cada usuario\n",
        "            es un ítem relevante en el top k ground truth o no\n",
        "        k (int): determina los primeros k ítems para calcular ndcg\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Dffbbc8L7qg"
      },
      "source": [
        "Definimos la función que evalúa en batches las métricas recall, precisión y NDCG para evitar problemas de memoria, procesando recomendaciones para un conjunto de usuarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "x6_741LlTMwI"
      },
      "outputs": [],
      "source": [
        "def get_metrics(model, edge_index, exclude_edge_indices, k, batch_size=512):\n",
        "    \"\"\"\n",
        "    Calcula las métricas de evaluación en batches para evitar desbordamiento de memoria.\n",
        "\n",
        "    Esta función evalúa el desempeño del modelo LightGCN calculando las métricas\n",
        "    de recall, precisión y NDCG en el top-k ítems recomendados para cada usuario.\n",
        "    Para manejar grandes conjuntos de datos, realiza el cálculo en lotes (batches)\n",
        "    de usuarios, excluyendo ítems ya vistos en entrenamiento para evitar sesgos en la evaluación.\n",
        "\n",
        "    Args:\n",
        "        model (LightGCN): modelo LightGCN entrenado\n",
        "        edge_index (torch.Tensor): lista 2 x N de aristas para el conjunto a evaluar\n",
        "        exclude_edge_indices (list[torch.Tensor]): lista de aristas a excluir del ranking (por ejemplo, entrenamiento)\n",
        "        k (int): número de ítems top-k para evaluar\n",
        "        batch_size (int): número de usuarios por lote\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precisión @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight.detach()\n",
        "    item_embedding = model.items_emb.weight.detach()\n",
        "\n",
        "    num_users = user_embedding.shape[0]\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    recall_list = []\n",
        "    precision_list = []\n",
        "    ndcg_list = []\n",
        "\n",
        "    for start in range(0, len(users), batch_size):\n",
        "        end = min(start + batch_size, len(users))\n",
        "        batch_users = users[start:end]\n",
        "\n",
        "        batch_user_emb = user_embedding[batch_users]  # (batch, emb_size)\n",
        "        rating = torch.matmul(batch_user_emb, item_embedding.T)  # (batch, num_items)\n",
        "\n",
        "        # Excluir ítems vistos en entrenamiento de la recomendación\n",
        "        for exclude_edge_index in exclude_edge_indices:\n",
        "            user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "            for i, user in enumerate(batch_users):\n",
        "                uid = user.item()\n",
        "                if uid in user_pos_items:\n",
        "                    rating[i, user_pos_items[uid]] = -(1 << 10)  # Excluir\n",
        "\n",
        "        _, top_K_items = torch.topk(rating, k=k)  # (batch, k)\n",
        "\n",
        "        r = []\n",
        "        for i, user in enumerate(batch_users):\n",
        "            uid = user.item()\n",
        "            ground_truth_items = test_user_pos_items[uid]\n",
        "            label = [item in ground_truth_items for item in top_K_items[i]]\n",
        "            r.append(label)\n",
        "\n",
        "        r = torch.tensor(np.array(r).astype('float'))\n",
        "\n",
        "        # Calcular métricas para el batch\n",
        "        batch_ground_truth = [test_user_pos_items[user.item()] for user in batch_users]\n",
        "        batch_recall, batch_precision = RecallPrecision_ATk(batch_ground_truth, r, k)\n",
        "        batch_ndcg = NDCGatK_r(batch_ground_truth, r, k)\n",
        "\n",
        "        recall_list.append(batch_recall)\n",
        "        precision_list.append(batch_precision)\n",
        "        ndcg_list.append(batch_ndcg)\n",
        "\n",
        "    # Promedio de métricas entre batches\n",
        "    recall = sum(recall_list) / len(recall_list)\n",
        "    precision = sum(precision_list) / len(precision_list)\n",
        "    ndcg = sum(ndcg_list) / len(ndcg_list)\n",
        "\n",
        "    return recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsMCd0iAL7qh"
      },
      "source": [
        "Definimos la función que realiza la evaluación completa del modelo, calculando la pérdida BPR y las métricas recall, precisión y NDCG sobre el conjunto de evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val=1e-6):\n",
        "    \"\"\"\n",
        "    Evalúa la pérdida del modelo y las métricas incluyendo recall, precisión y ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LightGCN): modelo LightGCN\n",
        "        edge_index (torch.Tensor): lista 2 x N de aristas para el conjunto a evaluar\n",
        "        sparse_edge_index (sparseTensor): matriz de adyacencia dispersa para el conjunto a evaluar\n",
        "        exclude_edge_indices ([tipo]): lista 2 x N de aristas para excluir de la evaluación\n",
        "        k (int): determina el top k de ítems para calcular las métricas\n",
        "        lambda_val (float): valor lambda para la pérdida BPR\n",
        "\n",
        "    Returns:\n",
        "        tuple: pérdida BPR, recall @ k, precisión @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # Obtener embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(sparse_edge_index)\n",
        "\n",
        "    edges = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
        "\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(model, edge_index, exclude_edge_indices, k, batch_size = 128)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_hGYor7L7qi"
      },
      "source": [
        "Definimos las variables para los parámetros clave para el entrenamiento y evaluación del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "outputs": [],
      "source": [
        "ITERATIONS = 1000\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "PATIENCE = 50\n",
        "K = 20\n",
        "LAMBDA = 1e-6\n",
        "NUM_USERS = len(user_mapping)\n",
        "NUM_ITEMS = len(book_mapping)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación definimos las funciones `train_model`, `hyperparameter_search` y `create_model`. Estas funciones nos permiten crear los modelos en base a la combinación de hiperparámetros escogida y entrenarlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ml7dgTIhLth"
      },
      "outputs": [],
      "source": [
        "def train_model(model, edge_index, train_edge_index, train_sparse_edge_index,\n",
        "                val_edge_index, val_sparse_edge_index,\n",
        "                iterations, batch_size, lr,\n",
        "                iters_per_eval, k_eval, lambda_reg, device,\n",
        "                iters_per_lr_decay=ITERS_PER_LR_DECAY,\n",
        "                early_stopping_patience=PATIENCE, early_stopping_delta=1e-4):\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    # Definimos el optimizador y el scheduler\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "    edge_index = edge_index.to(device)\n",
        "    train_edge_index = train_edge_index.to(device)\n",
        "    train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "    val_edge_index = val_edge_index.to(device)\n",
        "    val_sparse_edge_index = val_sparse_edge_index.to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    best_val_recall = -float('inf')\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "\n",
        "    for iter in range(iterations):\n",
        "        users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(train_sparse_edge_index)\n",
        "\n",
        "        user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(batch_size, train_edge_index)\n",
        "        user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "\n",
        "        users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "        pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
        "        neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "        train_loss = bpr_loss(users_emb_final, users_emb_0,\n",
        "                              pos_items_emb_final, pos_items_emb_0,\n",
        "                              neg_items_emb_final, neg_items_emb_0,\n",
        "                              lambda_reg)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Decay learning rate cada cierto número de iteraciones\n",
        "        if (iter + 1) % iters_per_lr_decay == 0:\n",
        "            scheduler.step()\n",
        "\n",
        "        if (iter + 1) % iters_per_eval == 0:\n",
        "            model.eval()\n",
        "            val_loss, recall, precision, ndcg = evaluation(\n",
        "                model, val_edge_index, val_sparse_edge_index, [train_edge_index], k_eval, lambda_reg)\n",
        "\n",
        "            print(f\"[Iteración {iter+1}/{iterations}] train_loss: {round(train_loss.item(), 5)}, \"\n",
        "                  f\"val_loss: {round(val_loss, 5)}, val_recall@{k_eval}: {round(recall, 5)}, \"\n",
        "                  f\"val_precision@{k_eval}: {round(precision, 5)}, val_ndcg@{k_eval}: {round(ndcg, 5)}\")\n",
        "\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            # Early stopping basado en recall\n",
        "            if recall > best_val_recall + early_stopping_delta:\n",
        "                best_val_recall = recall\n",
        "                best_model_state = model.state_dict()\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= early_stopping_patience:\n",
        "                    print(f\"Early stopping triggered at iteration {iter+1}\")\n",
        "                    break\n",
        "\n",
        "            model.train()\n",
        "\n",
        "    return train_losses, val_losses, best_val_recall, best_model_state\n",
        "\n",
        "\n",
        "def hyperparameter_search(create_model, hyperparams_grid, edge_index, train_edge_index,\n",
        "                          train_sparse_edge_index, val_edge_index, val_sparse_edge_index,\n",
        "                          iterations, iters_per_eval,\n",
        "                          k_eval, lambda_reg, device):\n",
        "\n",
        "    # Realiza una búsqueda de hiperparámetros en una cuadrícula definida por hyperparams_grid\n",
        "    keys, values = zip(*hyperparams_grid.items())\n",
        "    all_combinations = list(itertools.product(*values))\n",
        "\n",
        "    # Inicializa variables para almacenar los mejores resultados\n",
        "    best_score = -float('inf')\n",
        "    best_params = None\n",
        "    best_model_state = None\n",
        "\n",
        "    for v in all_combinations:\n",
        "        params = dict(zip(keys, v))\n",
        "        print(f\"\\nProbando hiperparámetros: {params}\")\n",
        "\n",
        "        model = create_model(\n",
        "            num_users=NUM_USERS,\n",
        "            num_items=NUM_ITEMS,\n",
        "            embedding_dim=params['embedding_dim'],\n",
        "            num_layers=params['num_layers']\n",
        "        )\n",
        "\n",
        "        train_losses, val_losses, val_recall, current_model_state = train_model(\n",
        "            model,\n",
        "            edge_index,\n",
        "            train_edge_index,\n",
        "            train_sparse_edge_index,\n",
        "            val_edge_index,\n",
        "            val_sparse_edge_index,\n",
        "            iterations=iterations,\n",
        "            batch_size=params['batch_size'],\n",
        "            lr=params['lr'],\n",
        "            iters_per_eval=iters_per_eval,\n",
        "            k_eval=k_eval,\n",
        "            lambda_reg=lambda_reg,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        print(f\"Validación recall@{k_eval}: {val_recall}\")\n",
        "\n",
        "        # Guardar el mejor modelo basado en recall\n",
        "        if val_recall > best_score:\n",
        "            best_score = val_recall\n",
        "            best_params = params\n",
        "            best_model_state = current_model_state\n",
        "\n",
        "    print(f\"\\nMejores hiperparámetros: {best_params} con recall@{k_eval}: {best_score}\")\n",
        "    return best_params, best_model_state\n",
        "\n",
        "def create_model(num_users, num_items, embedding_dim, num_layers):\n",
        "    return LightGCN(num_users, num_items, embedding_dim, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYZaW5lw7Eyi",
        "outputId": "602b50a0-d6d2-49a7-b24a-aae4dc3fbcf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 512, 'embedding_dim': 16, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69484, val_loss: -0.69226, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.6999, val_loss: -0.69369, val_recall@20: 0.07416, val_precision@20: 0.00476, val_ndcg@20: 0.06196\n",
            "[Iteración 600/1000] train_loss: -0.71585, val_loss: -0.70067, val_recall@20: 0.22206, val_precision@20: 0.01401, val_ndcg@20: 0.15182\n",
            "[Iteración 800/1000] train_loss: -0.75313, val_loss: -0.71838, val_recall@20: 0.3149, val_precision@20: 0.01993, val_ndcg@20: 0.19986\n",
            "[Iteración 1000/1000] train_loss: -0.79847, val_loss: -0.74975, val_recall@20: 0.36418, val_precision@20: 0.02282, val_ndcg@20: 0.22588\n",
            "Validación recall@20: 0.36417561026936024\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 512, 'embedding_dim': 16, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69382, val_loss: -0.69234, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69665, val_loss: -0.69285, val_recall@20: 0.07786, val_precision@20: 0.00481, val_ndcg@20: 0.06172\n",
            "[Iteración 600/1000] train_loss: -0.70479, val_loss: -0.69582, val_recall@20: 0.22415, val_precision@20: 0.01409, val_ndcg@20: 0.15226\n",
            "[Iteración 800/1000] train_loss: -0.72318, val_loss: -0.70368, val_recall@20: 0.32642, val_precision@20: 0.02048, val_ndcg@20: 0.21061\n",
            "[Iteración 1000/1000] train_loss: -0.74686, val_loss: -0.71746, val_recall@20: 0.38068, val_precision@20: 0.02385, val_ndcg@20: 0.23757\n",
            "Validación recall@20: 0.3806818181818182\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 512, 'embedding_dim': 32, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69674, val_loss: -0.69157, val_recall@20: 0.00071, val_precision@20: 4e-05, val_ndcg@20: 0.00071\n",
            "[Iteración 400/1000] train_loss: -0.70791, val_loss: -0.69446, val_recall@20: 0.1079, val_precision@20: 0.00674, val_ndcg@20: 0.08676\n",
            "[Iteración 600/1000] train_loss: -0.73959, val_loss: -0.70907, val_recall@20: 0.28157, val_precision@20: 0.01765, val_ndcg@20: 0.18251\n",
            "[Iteración 800/1000] train_loss: -0.83353, val_loss: -0.74792, val_recall@20: 0.38606, val_precision@20: 0.0239, val_ndcg@20: 0.2396\n",
            "[Iteración 1000/1000] train_loss: -0.95426, val_loss: -0.82364, val_recall@20: 0.42086, val_precision@20: 0.02614, val_ndcg@20: 0.2673\n",
            "Validación recall@20: 0.42086226851851855\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 512, 'embedding_dim': 32, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69493, val_loss: -0.6915, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.70078, val_loss: -0.69273, val_recall@20: 0.11162, val_precision@20: 0.00695, val_ndcg@20: 0.09188\n",
            "[Iteración 600/1000] train_loss: -0.72044, val_loss: -0.69961, val_recall@20: 0.27012, val_precision@20: 0.01689, val_ndcg@20: 0.17977\n",
            "[Iteración 800/1000] train_loss: -0.75147, val_loss: -0.71655, val_recall@20: 0.36861, val_precision@20: 0.02297, val_ndcg@20: 0.23782\n",
            "[Iteración 1000/1000] train_loss: -0.82312, val_loss: -0.74794, val_recall@20: 0.42101, val_precision@20: 0.02627, val_ndcg@20: 0.26391\n",
            "Validación recall@20: 0.4210069444444445\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 1024, 'embedding_dim': 16, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69591, val_loss: -0.69272, val_recall@20: 0.00355, val_precision@20: 0.00021, val_ndcg@20: 0.00244\n",
            "[Iteración 400/1000] train_loss: -0.70953, val_loss: -0.69817, val_recall@20: 0.1934, val_precision@20: 0.01197, val_ndcg@20: 0.13572\n",
            "[Iteración 600/1000] train_loss: -0.75144, val_loss: -0.72186, val_recall@20: 0.34226, val_precision@20: 0.02137, val_ndcg@20: 0.20998\n",
            "[Iteración 800/1000] train_loss: -0.83669, val_loss: -0.77481, val_recall@20: 0.40786, val_precision@20: 0.0254, val_ndcg@20: 0.24769\n",
            "[Iteración 1000/1000] train_loss: -0.9794, val_loss: -0.86368, val_recall@20: 0.43882, val_precision@20: 0.02739, val_ndcg@20: 0.26573\n",
            "Validación recall@20: 0.4388152356902358\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 1024, 'embedding_dim': 16, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69419, val_loss: -0.69246, val_recall@20: 0.00239, val_precision@20: 0.00012, val_ndcg@20: 0.00136\n",
            "[Iteración 400/1000] train_loss: -0.70051, val_loss: -0.69453, val_recall@20: 0.20004, val_precision@20: 0.0123, val_ndcg@20: 0.14154\n",
            "[Iteración 600/1000] train_loss: -0.71995, val_loss: -0.7046, val_recall@20: 0.35594, val_precision@20: 0.02202, val_ndcg@20: 0.21855\n",
            "[Iteración 800/1000] train_loss: -0.76297, val_loss: -0.7277, val_recall@20: 0.402, val_precision@20: 0.02494, val_ndcg@20: 0.24655\n",
            "[Iteración 1000/1000] train_loss: -0.82178, val_loss: -0.76643, val_recall@20: 0.42069, val_precision@20: 0.02631, val_ndcg@20: 0.25496\n",
            "Validación recall@20: 0.42069128787878785\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 1024, 'embedding_dim': 32, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69801, val_loss: -0.69183, val_recall@20: 0.00071, val_precision@20: 4e-05, val_ndcg@20: 0.00036\n",
            "[Iteración 400/1000] train_loss: -0.72329, val_loss: -0.70131, val_recall@20: 0.21974, val_precision@20: 0.01346, val_ndcg@20: 0.15\n",
            "[Iteración 600/1000] train_loss: -0.80708, val_loss: -0.74592, val_recall@20: 0.40703, val_precision@20: 0.02512, val_ndcg@20: 0.24383\n",
            "[Iteración 800/1000] train_loss: -1.00051, val_loss: -0.85742, val_recall@20: 0.4587, val_precision@20: 0.02846, val_ndcg@20: 0.28045\n",
            "[Iteración 1000/1000] train_loss: -1.31846, val_loss: -1.05473, val_recall@20: 0.48, val_precision@20: 0.02984, val_ndcg@20: 0.29793\n",
            "Validación recall@20: 0.4800018413299663\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.001, 'batch_size': 1024, 'embedding_dim': 32, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69526, val_loss: -0.69168, val_recall@20: 0.00024, val_precision@20: 4e-05, val_ndcg@20: 0.00014\n",
            "[Iteración 400/1000] train_loss: -0.70796, val_loss: -0.69629, val_recall@20: 0.20533, val_precision@20: 0.01267, val_ndcg@20: 0.14396\n",
            "[Iteración 600/1000] train_loss: -0.75151, val_loss: -0.71733, val_recall@20: 0.39128, val_precision@20: 0.02448, val_ndcg@20: 0.24404\n",
            "[Iteración 800/1000] train_loss: -0.83825, val_loss: -0.767, val_recall@20: 0.44118, val_precision@20: 0.02768, val_ndcg@20: 0.27105\n",
            "[Iteración 1000/1000] train_loss: -0.97305, val_loss: -0.85452, val_recall@20: 0.46713, val_precision@20: 0.02929, val_ndcg@20: 0.28677\n",
            "Validación recall@20: 0.4671256839225589\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 512, 'embedding_dim': 16, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69342, val_loss: -0.69229, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69487, val_loss: -0.69228, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 600/1000] train_loss: -0.69661, val_loss: -0.69256, val_recall@20: 0.00802, val_precision@20: 0.00051, val_ndcg@20: 0.00454\n",
            "[Iteración 800/1000] train_loss: -0.69907, val_loss: -0.69355, val_recall@20: 0.07231, val_precision@20: 0.00444, val_ndcg@20: 0.05899\n",
            "[Iteración 1000/1000] train_loss: -0.70402, val_loss: -0.69531, val_recall@20: 0.14066, val_precision@20: 0.00871, val_ndcg@20: 0.10726\n",
            "Validación recall@20: 0.14065788089225587\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 512, 'embedding_dim': 16, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69341, val_loss: -0.69228, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69386, val_loss: -0.69235, val_recall@20: 0.00036, val_precision@20: 4e-05, val_ndcg@20: 0.00014\n",
            "[Iteración 600/1000] train_loss: -0.69511, val_loss: -0.6925, val_recall@20: 0.02163, val_precision@20: 0.00132, val_ndcg@20: 0.01329\n",
            "[Iteración 800/1000] train_loss: -0.69722, val_loss: -0.69303, val_recall@20: 0.09771, val_precision@20: 0.00602, val_ndcg@20: 0.07791\n",
            "[Iteración 1000/1000] train_loss: -0.69977, val_loss: -0.69406, val_recall@20: 0.15039, val_precision@20: 0.0094, val_ndcg@20: 0.1168\n",
            "Validación recall@20: 0.150390625\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 512, 'embedding_dim': 32, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69452, val_loss: -0.69164, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69674, val_loss: -0.69179, val_recall@20: 0.00036, val_precision@20: 4e-05, val_ndcg@20: 0.00016\n",
            "[Iteración 600/1000] train_loss: -0.70053, val_loss: -0.69253, val_recall@20: 0.03492, val_precision@20: 0.00212, val_ndcg@20: 0.02436\n",
            "[Iteración 800/1000] train_loss: -0.70676, val_loss: -0.69478, val_recall@20: 0.11437, val_precision@20: 0.00699, val_ndcg@20: 0.0872\n",
            "[Iteración 1000/1000] train_loss: -0.71848, val_loss: -0.69933, val_recall@20: 0.17964, val_precision@20: 0.01119, val_ndcg@20: 0.1289\n",
            "Validación recall@20: 0.17964146675084175\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 512, 'embedding_dim': 32, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69353, val_loss: -0.69153, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69489, val_loss: -0.6915, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 600/1000] train_loss: -0.69665, val_loss: -0.69178, val_recall@20: 0.02482, val_precision@20: 0.00147, val_ndcg@20: 0.01653\n",
            "[Iteración 800/1000] train_loss: -0.69993, val_loss: -0.69267, val_recall@20: 0.10585, val_precision@20: 0.00658, val_ndcg@20: 0.08217\n",
            "[Iteración 1000/1000] train_loss: -0.70577, val_loss: -0.69442, val_recall@20: 0.15566, val_precision@20: 0.00974, val_ndcg@20: 0.1139\n",
            "Validación recall@20: 0.15566472011784513\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 1024, 'embedding_dim': 16, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69382, val_loss: -0.69244, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69559, val_loss: -0.69264, val_recall@20: 0.00204, val_precision@20: 0.00012, val_ndcg@20: 0.00054\n",
            "[Iteración 600/1000] train_loss: -0.69955, val_loss: -0.69417, val_recall@20: 0.06357, val_precision@20: 0.0039, val_ndcg@20: 0.0438\n",
            "[Iteración 800/1000] train_loss: -0.70759, val_loss: -0.69816, val_recall@20: 0.21547, val_precision@20: 0.01334, val_ndcg@20: 0.14251\n",
            "[Iteración 1000/1000] train_loss: -0.72143, val_loss: -0.70555, val_recall@20: 0.30959, val_precision@20: 0.01927, val_ndcg@20: 0.19483\n",
            "Validación recall@20: 0.3095933291245791\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 1024, 'embedding_dim': 16, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69338, val_loss: -0.69231, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69439, val_loss: -0.69249, val_recall@20: 0.00142, val_precision@20: 7e-05, val_ndcg@20: 0.00088\n",
            "[Iteración 600/1000] train_loss: -0.69627, val_loss: -0.69311, val_recall@20: 0.08097, val_precision@20: 0.00497, val_ndcg@20: 0.06295\n",
            "[Iteración 800/1000] train_loss: -0.69964, val_loss: -0.6946, val_recall@20: 0.16632, val_precision@20: 0.01021, val_ndcg@20: 0.12538\n",
            "[Iteración 1000/1000] train_loss: -0.70607, val_loss: -0.69753, val_recall@20: 0.25439, val_precision@20: 0.01586, val_ndcg@20: 0.17285\n",
            "Validación recall@20: 0.25439288720538716\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 1024, 'embedding_dim': 32, 'num_layers': 2}\n",
            "[Iteración 200/1000] train_loss: -0.69439, val_loss: -0.69166, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69838, val_loss: -0.69216, val_recall@20: 0.00583, val_precision@20: 0.00033, val_ndcg@20: 0.00447\n",
            "[Iteración 600/1000] train_loss: -0.70612, val_loss: -0.69501, val_recall@20: 0.11647, val_precision@20: 0.00716, val_ndcg@20: 0.09222\n",
            "[Iteración 800/1000] train_loss: -0.72327, val_loss: -0.70228, val_recall@20: 0.2091, val_precision@20: 0.01311, val_ndcg@20: 0.14684\n",
            "[Iteración 1000/1000] train_loss: -0.7489, val_loss: -0.71634, val_recall@20: 0.32782, val_precision@20: 0.0205, val_ndcg@20: 0.20897\n",
            "Validación recall@20: 0.3278159196127946\n",
            "\n",
            "Probando hiperparámetros: {'lr': 0.0005, 'batch_size': 1024, 'embedding_dim': 32, 'num_layers': 3}\n",
            "[Iteración 200/1000] train_loss: -0.69343, val_loss: -0.69164, val_recall@20: 0.0, val_precision@20: 0.0, val_ndcg@20: 0.0\n",
            "[Iteración 400/1000] train_loss: -0.69522, val_loss: -0.69194, val_recall@20: 0.00533, val_precision@20: 0.00028, val_ndcg@20: 0.00342\n",
            "[Iteración 600/1000] train_loss: -0.69891, val_loss: -0.69303, val_recall@20: 0.10247, val_precision@20: 0.00626, val_ndcg@20: 0.08475\n",
            "[Iteración 800/1000] train_loss: -0.70596, val_loss: -0.69628, val_recall@20: 0.20674, val_precision@20: 0.01265, val_ndcg@20: 0.15008\n",
            "[Iteración 1000/1000] train_loss: -0.71936, val_loss: -0.70244, val_recall@20: 0.32766, val_precision@20: 0.02041, val_ndcg@20: 0.20916\n",
            "Validación recall@20: 0.32766466750841755\n",
            "\n",
            "Mejores hiperparámetros: {'lr': 0.001, 'batch_size': 1024, 'embedding_dim': 32, 'num_layers': 2} con recall@20: 0.4800018413299663\n"
          ]
        }
      ],
      "source": [
        "# Grid de hiperparámetros para búsqueda\n",
        "hyperparams_grid = {\n",
        "    'lr': [1e-3, 5e-4],\n",
        "    'batch_size': [512, 1024],\n",
        "    'embedding_dim': [16, 32],\n",
        "    'num_layers': [2, 3]\n",
        "}\n",
        "\n",
        "# Ejecutar búsqueda de hiperparámetros\n",
        "best_params, best_model_state = hyperparameter_search(\n",
        "    create_model,\n",
        "    hyperparams_grid,\n",
        "    edge_index,\n",
        "    train_edge_index,\n",
        "    train_sparse_edge_index,\n",
        "    val_edge_index,\n",
        "    val_sparse_edge_index,\n",
        "    iterations=ITERATIONS,\n",
        "    iters_per_eval=ITERS_PER_EVAL,\n",
        "    k_eval=K,\n",
        "    lambda_reg=LAMBDA,\n",
        "    device=device\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
